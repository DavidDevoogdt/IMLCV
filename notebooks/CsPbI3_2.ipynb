{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT_DIR=PosixPath('/dodrio/scratch/projects/2024_026/IMLCV/src/IMLCV')\n",
      "node\n",
      "hortense\n",
      "setting python env for hortense\n",
      "executor='work_queue'\n",
      "wall_time_s=14160.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/subprocess.py:1893: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = _fork_exec(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting python env for hortense\n",
      "executor='work_queue'\n",
      "wall_time_s=3360.0\n",
      "setting python env for hortense\n",
      "executor='work_queue'\n",
      "wall_time_s=3360.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/subprocess.py:1893: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = _fork_exec(\n"
     ]
    }
   ],
   "source": [
    "from IMLCV.configs.config_general import config\n",
    "\n",
    "# config(\n",
    "#     env=\"local\",\n",
    "#     local_ref_threads=2,\n",
    "#     max_threads_local=10,\n",
    "# )\n",
    "\n",
    "N_TRAIN = 32\n",
    "\n",
    "config(\n",
    "    account=\"2024_117\",\n",
    "    singlepoint_nodes=2,\n",
    "    default_on_threads=False,\n",
    "    cpu_cluster=\"cpu_milan_rhel_9\",\n",
    "    training_cores=N_TRAIN,\n",
    "    walltime_training=\"04:00:00\",\n",
    "    walltime_ref=\"01:00:00\",\n",
    "    max_threads_local=5,\n",
    ")\n",
    "\n",
    "# config(\n",
    "\n",
    "#     singlepoint_nodes=4,\n",
    "#     walltime=\"12:00:00\",\n",
    "#     bootstrap=False,\n",
    "#     training_cores=32,\n",
    "\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out=' python  -u /dodrio/scratch/projects/2024_026/IMLCV/src/IMLCV/configs/bash_app_python.py --folder futs/fut_0 --file_in f_test_parallel_000.inp.p  --file_out  f_test_parallel_000.outp.p --inputs file1.txt file2.txt '\n",
      "out=' python  -u /dodrio/scratch/projects/2024_026/IMLCV/src/IMLCV/configs/bash_app_python.py --folder futs/fut_1 --file_in f_test_parallel_000.inp.p  --file_out  f_test_parallel_000.outp.p --inputs file1.txt file2.txt '\n",
      "out=' python  -u /dodrio/scratch/projects/2024_026/IMLCV/src/IMLCV/configs/bash_app_python.py --folder futs/fut_2 --file_in f_test_parallel_000.inp.p  --file_out  f_test_parallel_000.outp.p --inputs file1.txt file2.txt '\n",
      "out=' python  -u /dodrio/scratch/projects/2024_026/IMLCV/src/IMLCV/configs/bash_app_python.py --folder futs/fut_3 --file_in f_test_parallel_000.inp.p  --file_out  f_test_parallel_000.outp.p --inputs file1.txt file2.txt '\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from IMLCV.configs.bash_app_python import bash_app_python\n",
    "from IMLCV.configs.config_general import Executors\n",
    "\n",
    "\n",
    "def f_test_parallel(i, inputs=[]):\n",
    "    from time import sleep\n",
    "\n",
    "    with open(inputs[0], \"r\") as p:\n",
    "        i0 = int(p.read())\n",
    "\n",
    "    with open(inputs[1], \"r\") as p:\n",
    "        i1 = int(p.read())\n",
    "\n",
    "    # print(f\"i: {i=} {i0=} {inputs=}\")\n",
    "\n",
    "    sleep(2)\n",
    "\n",
    "    return i0 + i1 - 2 * i\n",
    "\n",
    "\n",
    "n = 4\n",
    "\n",
    "futs = []\n",
    "\n",
    "for i in range(n):\n",
    "    exec_folder = Path(\".\") / \"futs\" / f\"fut_{i}\"\n",
    "\n",
    "    exec_folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    f1 = exec_folder / \"file1.txt\"\n",
    "\n",
    "    with open(f1, \"w\") as p:\n",
    "        p.write(f\"{i}\")\n",
    "\n",
    "    f2 = exec_folder / \"file2.txt\"\n",
    "\n",
    "    with open(f2, \"w\") as p:\n",
    "        p.write(f\"{3 * i}\")\n",
    "\n",
    "    futs.append(\n",
    "        bash_app_python(\n",
    "            f_test_parallel,\n",
    "            pickle_extension=\"p\",\n",
    "            pass_files=True,\n",
    "            executors=Executors.threadpool,\n",
    "            # auto_log=True,\n",
    "        )(\n",
    "            i,\n",
    "            execution_folder=Path(\".\") / \"futs\" / f\"fut_{i}\",\n",
    "            inputs=[f1, f2],\n",
    "        )\n",
    "    )\n",
    "\n",
    "res = [f.result() for f in futs]\n",
    "\n",
    "assert res == [0, 2, 4, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 6]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from IMLCV.base.rounds import Rounds\n",
    "from IMLCV.examples.example_systems import CsPbI3_MACE_lattice\n",
    "from IMLCV.scheme import Scheme\n",
    "\n",
    "folder = Path(\"perovskites\") / \"CsPbI3_cell_002\"\n",
    "\n",
    "if folder.exists():\n",
    "    scheme = Scheme(rounds=Rounds.create(folder=folder, copy=False, new_folder=False))\n",
    "\n",
    "else:\n",
    "    md, refs = CsPbI3_MACE_lattice()\n",
    "\n",
    "    scheme = Scheme.from_refs(\n",
    "        mde=md,\n",
    "        refs=refs,\n",
    "        folder=folder,\n",
    "        steps=1000,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in scheme.rounds._i_vals(c=1, r=2):\n",
    "    scheme.rounds.validate_data(c=1, r=2, i=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.494341595946812"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IMLCV.base.UnitsConstants import angstrom, boltzmann, kelvin, kjmol\n",
    "\n",
    "300 * kelvin * boltzmann / kjmol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scheme.rounds.unzip_cv(cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk_size = 100\n",
    "\n",
    "# n = [15, 10, 6][scheme.bias.collective_variable.n - 1]\n",
    "\n",
    "# print(f\"{n=}\")\n",
    "\n",
    "# max_bias = 100 * kjmol\n",
    "# samples_per_bin = 200\n",
    "# min_samples_per_bin = 5\n",
    "\n",
    "# n_max = (2 * n) ** (scheme.bias.collective_variable.n)\n",
    "\n",
    "# print(f\"{n=} {n_max=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IMLCV.base.UnitsConstants import angstrom, kjmol\n",
    "\n",
    "r_cut = 6.0 * angstrom\n",
    "\n",
    "steps = 1000\n",
    "chunk_size = None\n",
    "macro_chunk = N_TRAIN * 16  # sampes per worker\n",
    "macro_chunk_nl = N_TRAIN * 128\n",
    "samples_per_bin = 20\n",
    "min_samples_per_bin = 5\n",
    "T_Scale = 10\n",
    "koopman = True\n",
    "eps = 0.15  # 10 percent overlap\n",
    "max_bias = 100 * kjmol\n",
    "num_cv_rnds = 2\n",
    "lag_n = 30\n",
    "koopman_wham = True\n",
    "n_max_descriptors = 1\n",
    "l_max_descriptor = 1\n",
    "alpha_rematch = 0.5\n",
    "ncv = 3\n",
    "min_cv = 2\n",
    "direct_bias = False\n",
    "\n",
    "max_cv_basis_fun = 2000\n",
    "\n",
    "bias_num_points = 5e4\n",
    "cv_num_points = 5e4\n",
    "num_sample_rounds = 5\n",
    "\n",
    "\n",
    "n_max = 1e3  # 30**3\n",
    "\n",
    "max_blocks = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_cv():\n",
    "    import jax\n",
    "    import jax.numpy as jnp\n",
    "\n",
    "    from IMLCV.base.CV import CV, CvTrans\n",
    "    from IMLCV.implementations.CV import (\n",
    "        LatticeInvariants2,\n",
    "        _cv_index,\n",
    "        get_sinkhorn_divergence_2,\n",
    "        sb_descriptor,\n",
    "        un_atomize,\n",
    "    )\n",
    "    from IMLCV.implementations.CvDiscovery import TransformerMAF\n",
    "\n",
    "    print(\"getting descriptor\")\n",
    "\n",
    "    descriptor = sb_descriptor(\n",
    "        r_cut=r_cut,\n",
    "        n_max=n_max_descriptors,\n",
    "        l_max=l_max_descriptor,\n",
    "        reshape=True,\n",
    "        reduce=True,\n",
    "    )\n",
    "\n",
    "    rounds = scheme.rounds\n",
    "\n",
    "    dlo_0 = rounds.data_loader(\n",
    "        cv_round=0,\n",
    "        start=0,\n",
    "        weight=False,\n",
    "        new_r_cut=r_cut,\n",
    "        time_series=True,\n",
    "        lag_n=20,\n",
    "    )\n",
    "\n",
    "    # print(f\"{dlo.nl=} {dlo.sp=}\")\n",
    "\n",
    "    print(\"computing soap descriptor\")\n",
    "\n",
    "    cv_0, cv_0_t = dlo_0.apply_cv(\n",
    "        descriptor,\n",
    "        x=dlo_0.sp,\n",
    "        x_t=dlo_0.sp_t,\n",
    "        nl=dlo_0.nl,\n",
    "        nl_t=dlo_0.nl,\n",
    "        macro_chunk=macro_chunk,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    print(\"sinkhorn div\")\n",
    "    tr = (\n",
    "        get_sinkhorn_divergence_2(\n",
    "            nli=dlo_0.nl,\n",
    "            pi=CV.stack(*[a[-1] for a in cv_0]),\n",
    "            alpha_rematch=alpha_rematch,\n",
    "            jacobian=True,\n",
    "            exp_factor=10.0,\n",
    "        )\n",
    "        * un_atomize\n",
    "    )\n",
    "\n",
    "    cv_1, cv_1_t = dlo_0.apply_cv(\n",
    "        tr,\n",
    "        x=cv_0,\n",
    "        x_t=cv_0_t,\n",
    "        nl=dlo_0.nl,\n",
    "        nl_t=dlo_0.nl,\n",
    "        macro_chunk=macro_chunk,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    from IMLCV.base.rounds import Covariances\n",
    "\n",
    "    calc_pi = True\n",
    "\n",
    "    cov = Covariances.create(\n",
    "        cv_0=cv_1,\n",
    "        cv_1=cv_1_t,\n",
    "        nl=dlo_0.nl,\n",
    "        nl_t=dlo_0.nl,\n",
    "        # w=w_tot,\n",
    "        # w_t=w_tot,\n",
    "        calc_pi=True,\n",
    "        only_diag=False,\n",
    "        symmetric=False,\n",
    "        chunk_size=chunk_size,\n",
    "        macro_chunk=macro_chunk,\n",
    "    )\n",
    "\n",
    "    argmask = jnp.arange(cov.C00.shape[0])\n",
    "\n",
    "    eps_pre = 1e-10\n",
    "    auto_cov_threshold = 0.1\n",
    "    verbose = True\n",
    "    max_features_pre = 1000\n",
    "\n",
    "    argmask_pre = jnp.logical_and(\n",
    "        jnp.diag(cov.C00) / jnp.max(jnp.diag(cov.C00)) > eps_pre**2,\n",
    "        jnp.diag(cov.C11) / jnp.max(jnp.diag(cov.C11)) > eps_pre**2,\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"{jnp.sum(argmask_pre)=} {jnp.sum(~argmask_pre)=}  {eps_pre=}\")\n",
    "\n",
    "    if jnp.sum(argmask_pre) == 0:\n",
    "        print(\n",
    "            f\"WARNING: no modes selectected through argmask pre {jnp.diag(cov.C00)/ jnp.max(jnp.diag(cov.C00))=} {jnp.diag(cov.C11)/ jnp.max(jnp.diag(cov.C11))=}\"\n",
    "        )\n",
    "\n",
    "    cov.C00 = cov.C00[argmask_pre, :][:, argmask_pre]\n",
    "    cov.C11 = cov.C11[argmask_pre, :][:, argmask_pre]\n",
    "    cov.C01 = cov.C01[argmask_pre, :][:, argmask_pre]\n",
    "    cov.C10 = cov.C10[argmask_pre, :][:, argmask_pre]\n",
    "\n",
    "    argmask = argmask[argmask_pre]\n",
    "\n",
    "    auto_cov = jnp.einsum(\n",
    "        \"i,i,i->i\",\n",
    "        jnp.diag(cov.C00) ** (-0.5),\n",
    "        jnp.diag(cov.C01),\n",
    "        jnp.diag(cov.C11) ** (-0.5),\n",
    "    )\n",
    "    argmask_cov = jnp.argsort(auto_cov, descending=True).reshape(-1)\n",
    "\n",
    "    if auto_cov_threshold is not None:\n",
    "        argmask_cov = argmask_cov[auto_cov[argmask_cov] > auto_cov_threshold]\n",
    "\n",
    "    if max_features_pre is not None:\n",
    "        if argmask_cov.shape[0] > max_features_pre:\n",
    "            argmask_cov = argmask_cov[:max_features_pre]\n",
    "            print(f\"reducing argmask_cov to {max_features_pre}\")\n",
    "\n",
    "    cov.C00 = cov.C00[argmask_cov, :][:, argmask_cov]\n",
    "    cov.C11 = cov.C11[argmask_cov, :][:, argmask_cov]\n",
    "    cov.C01 = cov.C01[argmask_cov, :][:, argmask_cov]\n",
    "    cov.C10 = cov.C10[argmask_cov, :][:, argmask_cov]\n",
    "\n",
    "    argmask = argmask[argmask_cov]\n",
    "\n",
    "    print(f\"{auto_cov[argmask_cov]=}\")\n",
    "\n",
    "    print(f\"{argmask_cov=}\")\n",
    "\n",
    "    from IMLCV.base.rounds import DataLoaderOutput\n",
    "\n",
    "    km_tr = CvTrans.from_cv_function(\n",
    "        DataLoaderOutput._transform,\n",
    "        static_argnames=[\"add_1\", \"add_1_pre\"],\n",
    "        add_1=False,\n",
    "        add_1_pre=False,\n",
    "        q=None,\n",
    "        pi=None,\n",
    "        argmask=argmask,\n",
    "    )\n",
    "\n",
    "    tot_flow = descriptor * tr * km_tr  # + LatticeInvariants2\n",
    "\n",
    "    print(f\"testing comp\")\n",
    "\n",
    "    cv_out, cv_out_t = dlo_0.apply_cv(\n",
    "        tot_flow,\n",
    "        x=dlo_0.sp,\n",
    "        x_t=dlo_0.sp_t,\n",
    "        nl=dlo_0.nl,\n",
    "        nl_t=dlo_0.nl,\n",
    "        macro_chunk=macro_chunk,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    print(f\"{cv_out[0].shape=}\")\n",
    "\n",
    "    start = 1\n",
    "\n",
    "    if scheme.rounds.cv == 0:\n",
    "        start = 0\n",
    "\n",
    "    if scheme.rounds.cv == 1:\n",
    "        start = 1\n",
    "\n",
    "    scheme.update_CV(\n",
    "        dlo_kwargs=dict(\n",
    "            out=cv_num_points,\n",
    "            num_cv_rounds=1,\n",
    "            time_series=True,\n",
    "            new_r_cut=r_cut,\n",
    "            num=num_cv_rnds + 1,\n",
    "            start=start,\n",
    "            lag_n=lag_n,\n",
    "            split_data=False,\n",
    "            chunk_size=chunk_size,\n",
    "            only_finished=True,\n",
    "            T_scale=T_Scale,\n",
    "            macro_chunk=macro_chunk,\n",
    "            samples_per_bin=samples_per_bin,\n",
    "            min_samples_per_bin=min_samples_per_bin,\n",
    "            macro_chunk_nl=macro_chunk_nl,\n",
    "            verbose=True,\n",
    "            n_max=n_max,\n",
    "            weight=True,\n",
    "            only_update_nl=True,\n",
    "            # reweight_to_fes=True,\n",
    "            reweight_inverse_bincount=True,\n",
    "            scale_times=False,\n",
    "        ),\n",
    "        transformer=TransformerMAF(\n",
    "            outdim=ncv,\n",
    "            descriptor=tot_flow,\n",
    "            pre_scale=False,\n",
    "            correct_bias=True,\n",
    "            use_ground_bias=True,\n",
    "            T_scale=T_Scale,\n",
    "            koopman_weighting=False,\n",
    "            method=\"tcca\",\n",
    "            solver=\"eig\",\n",
    "            max_features=max_cv_basis_fun,\n",
    "            max_features_pre=max_cv_basis_fun,  # if scheme0.rounds.cv > 0 else 100,\n",
    "            trans=None,\n",
    "            eps=1e-8,\n",
    "            eps_pre=1e-8,\n",
    "        ),\n",
    "        chunk_size=chunk_size,\n",
    "        plot=True,\n",
    "        new_r_cut=r_cut,\n",
    "        save_samples=True,\n",
    "        save_multiple_cvs=False,\n",
    "        test=False,\n",
    "        percentile=10,  # get 90.0% of the points\n",
    "        max_bias=max_bias,\n",
    "        macro_chunk=macro_chunk,\n",
    "        verbose=True,\n",
    "        n_max=n_max,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "def sample(eps=0.1):\n",
    "    cv_dim = scheme.rounds.get_collective_variable().n\n",
    "\n",
    "    n_umbrella = int(jnp.floor(max_blocks ** (1 / cv_dim)))\n",
    "\n",
    "    if n_umbrella > 12:\n",
    "        n_umbrella = 12\n",
    "\n",
    "    print(f\"n_umbrella: {n_umbrella}\")\n",
    "\n",
    "    scheme.inner_loop(\n",
    "        n=n_umbrella,\n",
    "        rnds=num_sample_rounds if scheme.rounds.cv > 1 else 3,\n",
    "        steps=1000,\n",
    "        init=0,\n",
    "        eps_umbrella=eps,\n",
    "        fes_bias_rnds=num_cv_rnds,\n",
    "        chunk_size=chunk_size,\n",
    "        macro_chunk=macro_chunk,\n",
    "        samples_per_bin=samples_per_bin,\n",
    "        min_samples_per_bin=min_samples_per_bin,\n",
    "        max_bias=max_bias,\n",
    "        n_max_fes=n_max,\n",
    "        convergence_kl=0.05,\n",
    "        thermolib=False,\n",
    "        T_scale=T_Scale,\n",
    "        koopman=koopman,\n",
    "        koopman_wham=koopman_wham,\n",
    "        out=bias_num_points,\n",
    "        direct_bias=direct_bias,\n",
    "        # first_round_without_bias=scheme.rounds.cv == 1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fes_bias():\n",
    "    bias = scheme.FESBias(\n",
    "        plot=True,\n",
    "        samples_per_bin=samples_per_bin,\n",
    "        min_samples_per_bin=min_samples_per_bin,\n",
    "        chunk_size=chunk_size,\n",
    "        macro_chunk=macro_chunk,\n",
    "        num_rnds=num_cv_rnds,\n",
    "        vmax=max_bias,\n",
    "        max_bias=max_bias,\n",
    "        only_finished=True,\n",
    "        n_max=n_max,\n",
    "        thermolib=False,\n",
    "        out=bias_num_points,\n",
    "        T_scale=T_Scale,\n",
    "        # divide_by_histogram=True,\n",
    "        lag_n=lag_n,\n",
    "        koopman_wham=koopman_wham,\n",
    "        koopman=koopman,\n",
    "        direct_bias=direct_bias,\n",
    "    )\n",
    "\n",
    "    scheme.rounds.add_round(bias=bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scheme.rounds.cv == 0:\n",
    "    update_cv()\n",
    "\n",
    "for i in range(10):\n",
    "    sample(eps=eps)\n",
    "    update_cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimating bias from koopman Theory!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process WorkQueue-Submit-Process:\n",
      "Process WorkQueue-Submit-Process:\n",
      "Process WorkQueue-Submit-Process:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/site-packages/parsl/process_loggers.py\", line 26, in wrapped\n",
      "    r = func(*args, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/site-packages/parsl/executors/workqueue/executor.py\", line 970, in _work_queue_submit_wait\n",
      "    t = q.wait(1)\n",
      "        ^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/site-packages/ndcctools/work_queue.py\", line 1914, in wait\n",
      "    return self.wait_for_tag(None, timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/site-packages/ndcctools/work_queue.py\", line 1928, in wait_for_tag\n",
      "    task_pointer = work_queue_wait_for_tag(self._work_queue, tag, timeout)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/site-packages/ndcctools/cwork_queue.py\", line 543, in work_queue_wait_for_tag\n",
      "    return _cwork_queue.work_queue_wait_for_tag(q, tag, timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/site-packages/parsl/process_loggers.py\", line 26, in wrapped\n",
      "    r = func(*args, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/site-packages/parsl/executors/workqueue/executor.py\", line 970, in _work_queue_submit_wait\n",
      "    t = q.wait(1)\n",
      "        ^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/site-packages/ndcctools/work_queue.py\", line 1914, in wait\n",
      "    return self.wait_for_tag(None, timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/site-packages/ndcctools/work_queue.py\", line 1928, in wait_for_tag\n",
      "    task_pointer = work_queue_wait_for_tag(self._work_queue, tag, timeout)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/site-packages/ndcctools/cwork_queue.py\", line 543, in work_queue_wait_for_tag\n",
      "    return _cwork_queue.work_queue_wait_for_tag(q, tag, timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/site-packages/parsl/process_loggers.py\", line 26, in wrapped\n",
      "    r = func(*args, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/site-packages/parsl/executors/workqueue/executor.py\", line 861, in _work_queue_submit_wait\n",
      "    task = task_queue.get(timeout=1)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/multiprocessing/queues.py\", line 113, in get\n",
      "    if not self._poll(timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/multiprocessing/connection.py\", line 440, in _poll\n",
      "    r = wait([self], timeout)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/multiprocessing/connection.py\", line 1136, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: using plain-text when communicating with workers.\n",
      "warning: use encryption with a key and cert when creating the manager.\n",
      "warning: using plain-text when communicating with workers.\n",
      "warning: use encryption with a key and cert when creating the manager.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_fes_bias\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mget_fes_bias\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_fes_bias\u001b[39m():\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     bias = \u001b[43mscheme\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFESBias\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43msamples_per_bin\u001b[49m\u001b[43m=\u001b[49m\u001b[43msamples_per_bin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmin_samples_per_bin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmin_samples_per_bin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmacro_chunk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmacro_chunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_rnds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_cv_rnds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvmax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43monly_finished\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_max\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mthermolib\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbias_num_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43mT_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mT_Scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# divide_by_histogram=True,\u001b[39;49;00m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlag_n\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlag_n\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkoopman_wham\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkoopman_wham\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkoopman\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkoopman\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdirect_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdirect_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     scheme.rounds.add_round(bias=bias)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dodrio/scratch/projects/2024_026/IMLCV/src/IMLCV/scheme.py:67\u001b[39m, in \u001b[36mScheme.FESBias\u001b[39m\u001b[34m(self, rnd, cv_round, chunk_size, **plotkwargs)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mFESBias\u001b[39m(\n\u001b[32m     58\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     59\u001b[39m     rnd: \u001b[38;5;28mint\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     62\u001b[39m     **plotkwargs,\n\u001b[32m     63\u001b[39m ) -> Bias:\n\u001b[32m     64\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"replace the current md bias with the computed FES from current\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[33;03m    round.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mObservable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrnd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrnd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcv_round\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfes_bias\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mplotkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dodrio/scratch/projects/2024_026/IMLCV/src/IMLCV/base/Observable.py:624\u001b[39m, in \u001b[36mObservable.fes_bias\u001b[39m\u001b[34m(self, plot, fes, max_bias, choice, num_rnds, start_r, rbf_kernel, rbf_degree, samples_per_bin, min_samples_per_bin, chunk_size, macro_chunk, update_bounding_box, n_max, min_traj_length, margin, only_finished, shmap, thermolib, lag_n, out, T_scale, vmax, koopman, verbose, koopman_wham, executors, direct_bias)\u001b[39m\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    622\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mestimating bias from koopman Theory!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m624\u001b[39m     fes_bias_tot = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfes_nd_weights\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_rnds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_rnds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlag_n\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlag_n\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstart_r\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_r\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmin_traj_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmin_traj_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m        \u001b[49m\u001b[43monly_finished\u001b[49m\u001b[43m=\u001b[49m\u001b[43monly_finished\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmacro_chunk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmacro_chunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[43m        \u001b[49m\u001b[43mT_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mT_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_max\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkoopman\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkoopman\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# divide_by_histogram=divide_by_histogram,\u001b[39;49;00m\n\u001b[32m    637\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    638\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkooopman_wham\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkoopman_wham\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    640\u001b[39m \u001b[43m        \u001b[49m\u001b[43msamples_per_bin\u001b[49m\u001b[43m=\u001b[49m\u001b[43msamples_per_bin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    641\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmin_samples_per_bin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmin_samples_per_bin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    642\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexecutors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexecutors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    643\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdirect_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdirect_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    644\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m fes_bias_tot\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dodrio/scratch/projects/2024_026/IMLCV/src/IMLCV/base/Observable.py:540\u001b[39m, in \u001b[36mObservable.fes_nd_weights\u001b[39m\u001b[34m(self, num_rnds, out, lag_n, start_r, min_traj_length, only_finished, chunk_size, macro_chunk, T_scale, n_max, cv_round, directory, koopman, verbose, max_bias, kooopman_wham, samples_per_bin, min_samples_per_bin, executors, direct_bias)\u001b[39m\n\u001b[32m    530\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m executors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    531\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Observable._fes_nd_weights(**kwargs)\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbash_app_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m    \u001b[49m\u001b[43mObservable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_fes_nd_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecutors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mExecutors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m    \u001b[49m\u001b[43mremove_stdout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    539\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecution_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m540\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/concurrent/futures/_base.py:451\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__get_result()\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_condition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/threading.py:355\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    354\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "get_fes_bias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
