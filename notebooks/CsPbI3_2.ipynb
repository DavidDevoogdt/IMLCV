{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT_DIR=PosixPath('/dodrio/scratch/projects/2024_026/IMLCV/src/IMLCV')\n",
      "node\n",
      "hortense\n",
      "setting python env for hortense\n",
      "executor='work_queue'\n",
      "wall_time_s=14160.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/subprocess.py:1893: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = _fork_exec(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting python env for hortense\n",
      "executor='work_queue'\n",
      "wall_time_s=172560.0\n",
      "setting python env for hortense\n",
      "executor='work_queue'\n",
      "wall_time_s=14160.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/subprocess.py:1893: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = _fork_exec(\n",
      "/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/subprocess.py:1893: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = _fork_exec(\n"
     ]
    }
   ],
   "source": [
    "from IMLCV.configs.config_general import config\n",
    "\n",
    "# config(\n",
    "#     env=\"local\",\n",
    "#     local_ref_threads=2,\n",
    "#     max_threads_local=10,\n",
    "# )\n",
    "\n",
    "N_TRAIN = 32\n",
    "\n",
    "config(\n",
    "    account=\"2024_117\",\n",
    "    singlepoint_nodes=4,\n",
    "    default_on_threads=False,\n",
    "    cpu_cluster=\"cpu_milan_rhel_9\",\n",
    "    training_cores=N_TRAIN,\n",
    ")\n",
    "\n",
    "# config(\n",
    "\n",
    "#     singlepoint_nodes=4,\n",
    "#     walltime=\"12:00:00\",\n",
    "#     bootstrap=False,\n",
    "#     training_cores=32,\n",
    "\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from IMLCV.base.rounds import Rounds\n",
    "from IMLCV.examples.example_systems import CsPbI3_MACE_lattice\n",
    "from IMLCV.scheme import Scheme\n",
    "\n",
    "folder = Path(\"perovskites\") / \"CsPbI3_cell_002\"\n",
    "\n",
    "if folder.exists():\n",
    "    scheme = Scheme(rounds=Rounds.create(folder=folder, copy=False, new_folder=False))\n",
    "\n",
    "else:\n",
    "    md, refs = CsPbI3_MACE_lattice()\n",
    "\n",
    "    scheme = Scheme.from_refs(\n",
    "        mde=md,\n",
    "        refs=refs,\n",
    "        folder=folder,\n",
    "        steps=1000,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.494341595946812"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IMLCV.base.UnitsConstants import angstrom, boltzmann, kelvin, kjmol\n",
    "\n",
    "300 * kelvin * boltzmann / kjmol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scheme.rounds.unzip_cv(cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk_size = 100\n",
    "\n",
    "# n = [15, 10, 6][scheme.bias.collective_variable.n - 1]\n",
    "\n",
    "# print(f\"{n=}\")\n",
    "\n",
    "# max_bias = 100 * kjmol\n",
    "# samples_per_bin = 200\n",
    "# min_samples_per_bin = 5\n",
    "\n",
    "# n_max = (2 * n) ** (scheme.bias.collective_variable.n)\n",
    "\n",
    "# print(f\"{n=} {n_max=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from molmod.units import angstrom, kjmol\n",
    "\n",
    "r_cut = 6.0 * angstrom\n",
    "\n",
    "steps = 1000\n",
    "chunk_size = None\n",
    "macro_chunk = N_TRAIN * 16  # sampes per worker\n",
    "macro_chunk_nl = N_TRAIN * 128\n",
    "samples_per_bin = 100\n",
    "min_samples_per_bin = 10\n",
    "T_Scale = 10\n",
    "koopman = True\n",
    "eps = 0.15  # 10 percent overlap\n",
    "max_bias = 100 * kjmol\n",
    "num_cv_rnds = 2\n",
    "lag_n = 30\n",
    "koopman_wham = True\n",
    "n_max_descriptors = 1\n",
    "l_max_descriptor = 1\n",
    "alpha_rematch = 0.2\n",
    "ncv = 3\n",
    "min_cv = 2\n",
    "direct_bias = False\n",
    "\n",
    "max_cv_basis_fun = 2000\n",
    "\n",
    "bias_num_points = 5e4\n",
    "cv_num_points = 5e4\n",
    "num_sample_rounds = 5\n",
    "\n",
    "\n",
    "n_max = 1e3  # 30**3\n",
    "\n",
    "max_blocks = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_max_descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_cv():\n",
    "    import jax\n",
    "    import jax.numpy as jnp\n",
    "\n",
    "    from IMLCV.base.CV import CV, CvTrans\n",
    "    from IMLCV.implementations.CV import LatticeInvariants2, _cv_index, get_sinkhorn_divergence_2, sb_descriptor\n",
    "    from IMLCV.implementations.CvDiscovery import TransformerMAF\n",
    "\n",
    "    print(\"getting descriptor\")\n",
    "\n",
    "    descriptor = sb_descriptor(\n",
    "        r_cut=r_cut,\n",
    "        n_max=n_max_descriptors,\n",
    "        l_max=l_max_descriptor,\n",
    "        reshape=True,\n",
    "        reduce=True,\n",
    "    )\n",
    "\n",
    "    rounds = scheme.rounds\n",
    "\n",
    "    dlo_0 = rounds.data_loader(\n",
    "        cv_round=0,\n",
    "        start=0,\n",
    "        weight=False,\n",
    "        new_r_cut=r_cut,\n",
    "        time_series=True,\n",
    "        lag_n=20,\n",
    "    )\n",
    "\n",
    "    # print(f\"{dlo.nl=} {dlo.sp=}\")\n",
    "\n",
    "    print(\"computing soap descriptor\")\n",
    "\n",
    "    cv_0, cv_0_t = dlo_0.apply_cv(\n",
    "        descriptor,\n",
    "        x=dlo_0.sp,\n",
    "        x_t=dlo_0.sp_t,\n",
    "        nl=dlo_0.nl,\n",
    "        nl_t=dlo_0.nl,\n",
    "        macro_chunk=macro_chunk,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    print(\"sinkhorn div\")\n",
    "    tr = get_sinkhorn_divergence_2(\n",
    "        nli=dlo_0.nl,\n",
    "        pi=CV.stack(*[a[-1] for a in cv_0]),\n",
    "        alpha_rematch=alpha_rematch,\n",
    "        jacobian=False,\n",
    "    )\n",
    "\n",
    "    cv_1, cv_1_t = dlo_0.apply_cv(\n",
    "        tr,\n",
    "        x=cv_0,\n",
    "        x_t=cv_0_t,\n",
    "        nl=dlo_0.nl,\n",
    "        nl_t=dlo_0.nl,\n",
    "        macro_chunk=macro_chunk,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # cv_2 = cv_1\n",
    "    # cv_2_t=cv_1_t\n",
    "\n",
    "    print(\"computing nonzero elems\")\n",
    "\n",
    "    # cv_2_stack = CV.stack(*cv_2)\n",
    "\n",
    "    # idx = jnp.argwhere(jnp.std(cv_2_stack.cv,axis=0) > 1e-10)\n",
    "\n",
    "    # @jax.vmap\n",
    "    # def f(x):\n",
    "    #     return jnp.ravel_multi_index(x, cv_2_stack.shape[1:], mode=\"wrap\")\n",
    "\n",
    "    # idx = f(idx)\n",
    "\n",
    "    # print(f\"{idx.shape=}\")\n",
    "\n",
    "    # sl = CvTrans.from_cv_function(_cv_index, indices=idx)\n",
    "\n",
    "    # cv_3, cv_3_t = dlo_0.apply_cv(\n",
    "    #     sl,\n",
    "    #     x=cv_,\n",
    "    #     x_t=cv_2_t,\n",
    "    #     macro_chunk=macro_chunk,\n",
    "    #     verbose=True,\n",
    "    # )\n",
    "\n",
    "    km = dlo_0.koopman_model(\n",
    "        cv_0=cv_1,\n",
    "        cv_tau=cv_1_t,\n",
    "        method=\"tcca\",\n",
    "        calc_pi=False,\n",
    "        add_1=True,\n",
    "        trans=None,\n",
    "        chunk_size=chunk_size,\n",
    "        macro_chunk=macro_chunk,\n",
    "        verbose=True,\n",
    "        out_dim=-1,\n",
    "        symmetric=True,\n",
    "        correlation=True,\n",
    "        eps=1e-8,\n",
    "        eps_pre=1e-8,\n",
    "        max_features_pre=500,\n",
    "    )\n",
    "\n",
    "    from IMLCV.base.rounds import DataLoaderOutput\n",
    "\n",
    "    mask = km.s > 0.1\n",
    "\n",
    "    o = km.W0.T\n",
    "\n",
    "    o = o[:, mask]\n",
    "\n",
    "    print(f\"{jnp.sum(mask)=}\")\n",
    "\n",
    "    km_tr = CvTrans.from_cv_function(\n",
    "        DataLoaderOutput._transform,\n",
    "        static_argnames=[\"add_1\", \"add_1_pre\"],\n",
    "        add_1=False,\n",
    "        add_1_pre=False,\n",
    "        q=o,\n",
    "        pi=km.cov.pi_0,\n",
    "        argmask=km.argmask,\n",
    "    )\n",
    "\n",
    "    if km.trans is not None:\n",
    "        km_tr = km.trans * km_tr\n",
    "\n",
    "    tot_flow = (descriptor * tr * km_tr) + LatticeInvariants2\n",
    "\n",
    "    print(f\"testing comp\")\n",
    "\n",
    "    cv_out, cv_out_t = dlo_0.apply_cv(\n",
    "        tot_flow,\n",
    "        x=dlo_0.sp,\n",
    "        x_t=dlo_0.sp_t,\n",
    "        nl=dlo_0.nl,\n",
    "        nl_t=dlo_0.nl,\n",
    "        macro_chunk=macro_chunk,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    print(f\"{cv_out[0].shape=}\")\n",
    "\n",
    "    start = 1\n",
    "\n",
    "    if scheme.rounds.cv == 0:\n",
    "        start = 0\n",
    "\n",
    "    if scheme.rounds.cv == 1:\n",
    "        start = 1\n",
    "\n",
    "    scheme.update_CV(\n",
    "        dlo_kwargs=dict(\n",
    "            out=cv_num_points,\n",
    "            num_cv_rounds=1,\n",
    "            time_series=True,\n",
    "            new_r_cut=r_cut,\n",
    "            num=num_cv_rnds + 1,\n",
    "            start=start,\n",
    "            lag_n=lag_n,\n",
    "            split_data=False,\n",
    "            chunk_size=chunk_size,\n",
    "            only_finished=True,\n",
    "            T_scale=T_Scale,\n",
    "            macro_chunk=macro_chunk,\n",
    "            samples_per_bin=samples_per_bin,\n",
    "            min_samples_per_bin=min_samples_per_bin,\n",
    "            macro_chunk_nl=macro_chunk_nl,\n",
    "            verbose=True,\n",
    "            n_max=n_max,\n",
    "            weight=True,\n",
    "            only_update_nl=True,\n",
    "            # reweight_to_fes=True,\n",
    "            reweight_inverse_bincount=True,\n",
    "            scale_times=False,\n",
    "        ),\n",
    "        transformer=TransformerMAF(\n",
    "            outdim=ncv,\n",
    "            descriptor=tot_flow,\n",
    "            pre_scale=False,\n",
    "            correct_bias=True,\n",
    "            use_ground_bias=True,\n",
    "            T_scale=T_Scale,\n",
    "            koopman_weighting=False,\n",
    "            method=\"tcca\",\n",
    "            solver=\"eig\",\n",
    "            max_features=max_cv_basis_fun,\n",
    "            max_features_pre=max_cv_basis_fun,  # if scheme0.rounds.cv > 0 else 100,\n",
    "            trans=None,\n",
    "            eps=1e-8,\n",
    "            eps_pre=1e-8,\n",
    "        ),\n",
    "        chunk_size=chunk_size,\n",
    "        plot=True,\n",
    "        new_r_cut=r_cut,\n",
    "        save_samples=True,\n",
    "        save_multiple_cvs=False,\n",
    "        test=False,\n",
    "        percentile=10,  # get 90.0% of the points\n",
    "        max_bias=max_bias,\n",
    "        macro_chunk=macro_chunk,\n",
    "        verbose=True,\n",
    "        n_max=n_max,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "def sample(eps=0.1):\n",
    "    cv_dim = scheme.rounds.get_collective_variable().n\n",
    "\n",
    "    n_umbrella = int(jnp.floor(max_blocks ** (1 / cv_dim)))\n",
    "\n",
    "    if n_umbrella > 20:\n",
    "        n_umbrella = 20\n",
    "\n",
    "    print(f\"n_umbrella: {n_umbrella}\")\n",
    "\n",
    "    scheme.inner_loop(\n",
    "        n=n_umbrella,\n",
    "        rnds=num_sample_rounds if scheme.rounds.cv > 1 else 3,\n",
    "        steps=1000,\n",
    "        init=0,\n",
    "        eps_umbrella=eps,\n",
    "        fes_bias_rnds=num_cv_rnds,\n",
    "        chunk_size=chunk_size,\n",
    "        macro_chunk=macro_chunk,\n",
    "        samples_per_bin=samples_per_bin,\n",
    "        min_samples_per_bin=min_samples_per_bin,\n",
    "        max_bias=max_bias,\n",
    "        n_max_fes=n_max,\n",
    "        convergence_kl=0.05,\n",
    "        thermolib=False,\n",
    "        T_scale=T_Scale,\n",
    "        koopman=koopman,\n",
    "        koopman_wham=koopman_wham,\n",
    "        out=bias_num_points,\n",
    "        direct_bias=direct_bias,\n",
    "        first_round_without_bias=scheme.rounds.cv == 1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fes_bias():\n",
    "    bias = scheme.FESBias(\n",
    "        plot=True,\n",
    "        samples_per_bin=samples_per_bin,\n",
    "        min_samples_per_bin=min_samples_per_bin,\n",
    "        chunk_size=chunk_size,\n",
    "        macro_chunk=macro_chunk,\n",
    "        num_rnds=num_cv_rnds,\n",
    "        vmax=max_bias,\n",
    "        max_bias=max_bias,\n",
    "        only_finished=True,\n",
    "        n_max=n_max,\n",
    "        thermolib=False,\n",
    "        out=bias_num_points,\n",
    "        T_scale=T_Scale,\n",
    "        # divide_by_histogram=True,\n",
    "        lag_n=lag_n,\n",
    "        koopman_wham=koopman_wham,\n",
    "        koopman=koopman,\n",
    "        direct_bias=direct_bias,\n",
    "    )\n",
    "\n",
    "    scheme.rounds.add_round(bias=bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_umbrella: 20\n",
      "cv_round=1\n",
      "i_0=1\n",
      "running round i=1 with 1000 steps\n",
      "running first round wihtout biases\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process WorkQueue-Submit-Process:\n",
      "Process WorkQueue-Submit-Process:\n",
      "Process WorkQueue-Submit-Process:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/site-packages/parsl/process_loggers.py\", line 26, in wrapped\n",
      "    r = func(*args, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/site-packages/parsl/executors/workqueue/executor.py\", line 861, in _work_queue_submit_wait\n",
      "    task = task_queue.get(timeout=1)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/multiprocessing/queues.py\", line 113, in get\n",
      "    if not self._poll(timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/multiprocessing/connection.py\", line 440, in _poll\n",
      "    r = wait([self], timeout)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/multiprocessing/connection.py\", line 1136, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/site-packages/parsl/process_loggers.py\", line 26, in wrapped\n",
      "    r = func(*args, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/site-packages/parsl/executors/workqueue/executor.py\", line 861, in _work_queue_submit_wait\n",
      "    task = task_queue.get(timeout=1)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/multiprocessing/queues.py\", line 113, in get\n",
      "    if not self._poll(timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/multiprocessing/connection.py\", line 440, in _poll\n",
      "    r = wait([self], timeout)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/multiprocessing/connection.py\", line 1136, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/site-packages/parsl/process_loggers.py\", line 26, in wrapped\n",
      "    r = func(*args, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/site-packages/parsl/executors/workqueue/executor.py\", line 861, in _work_queue_submit_wait\n",
      "    task = task_queue.get(timeout=1)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/multiprocessing/queues.py\", line 113, in get\n",
      "    if not self._poll(timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/multiprocessing/connection.py\", line 440, in _poll\n",
      "    r = wait([self], timeout)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/multiprocessing/connection.py\", line 1136, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "if scheme.rounds.cv == 0:\n",
    "    update_cv()\n",
    "\n",
    "for i in range(10):\n",
    "    sample(eps=eps)\n",
    "    update_cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimating bias from koopman Theory!\n"
     ]
    }
   ],
   "source": [
    "get_fes_bias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
