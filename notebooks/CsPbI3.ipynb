{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT_DIR=PosixPath('/dodrio/scratch/projects/2024_026/IMLCV/src/IMLCV')\n",
      "node\n",
      "hortense\n",
      "setting python env for hortense\n",
      "executor='work_queue'\n",
      "wall_time_s=14160.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/subprocess.py:1893: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = _fork_exec(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting python env for hortense\n",
      "executor='work_queue'\n",
      "wall_time_s=172560.0\n",
      "setting python env for hortense\n",
      "executor='work_queue'\n",
      "wall_time_s=14160.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/subprocess.py:1893: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = _fork_exec(\n",
      "/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/subprocess.py:1893: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = _fork_exec(\n",
      "/dodrio/scratch/projects/2024_026/IMLCV/micromamba/envs/py312/lib/python3.12/subprocess.py:1893: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = _fork_exec(\n"
     ]
    }
   ],
   "source": [
    "from IMLCV.configs.config_general import config\n",
    "\n",
    "# config(\n",
    "#     env=\"local\",\n",
    "#     local_ref_threads=2,\n",
    "#     max_threads_local=10,\n",
    "# )\n",
    "\n",
    "N_TRAIN = 64\n",
    "\n",
    "config(\n",
    "    account=\"2024_117\",\n",
    "    singlepoint_nodes=4,\n",
    "    default_on_threads=False,\n",
    "    cpu_cluster=\"cpu_milan_rhel_9\",\n",
    "    training_cores=N_TRAIN,\n",
    ")\n",
    "\n",
    "# config(\n",
    "\n",
    "#     singlepoint_nodes=4,\n",
    "#     walltime=\"12:00:00\",\n",
    "#     bootstrap=False,\n",
    "#     training_cores=32,\n",
    "\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from IMLCV.base.rounds import Rounds\n",
    "from IMLCV.examples.example_systems import CsPbI3_MACE_lattice\n",
    "from IMLCV.scheme import Scheme\n",
    "\n",
    "folder = Path(\"perovskites\") / \"CsPbI3_cell\"\n",
    "\n",
    "if folder.exists():\n",
    "    scheme = Scheme(rounds=Rounds.create(folder=folder, copy=False, new_folder=False))\n",
    "\n",
    "else:\n",
    "    md, refs = CsPbI3_MACE_lattice()\n",
    "\n",
    "    scheme = Scheme.from_refs(\n",
    "        mde=md,\n",
    "        refs=refs,\n",
    "        folder=folder,\n",
    "        steps=1000,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.494341595946812"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IMLCV.base.UnitsConstants import angstrom, boltzmann, kelvin, kjmol\n",
    "\n",
    "300 * kelvin * boltzmann / kjmol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzipping cv=2\n"
     ]
    }
   ],
   "source": [
    "scheme.rounds.unzip_cv(cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=6\n",
      "n=6 n_max=1728\n"
     ]
    }
   ],
   "source": [
    "steps = 1000\n",
    "\n",
    "chunk_size = 100\n",
    "\n",
    "n = [15, 10, 6][scheme.bias.collective_variable.n - 1]\n",
    "\n",
    "print(f\"{n=}\")\n",
    "\n",
    "max_bias = 100 * kjmol\n",
    "samples_per_bin = 200\n",
    "min_samples_per_bin = 5\n",
    "\n",
    "n_max = (2 * n) ** (scheme.bias.collective_variable.n)\n",
    "\n",
    "print(f\"{n=} {n_max=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from molmod.units import angstrom, kjmol\n",
    "\n",
    "r_cut = 5.0 * angstrom\n",
    "\n",
    "chunk_size = None\n",
    "macro_chunk = N_TRAIN * 16  # sampes per worker\n",
    "macro_chunk_nl = N_TRAIN * 128\n",
    "samples_per_bin = 50\n",
    "min_samples_per_bin = 10\n",
    "T_Scale = 10\n",
    "koopman = True\n",
    "eps = 0.10  # 10 percent overlap\n",
    "max_bias = 100 * kjmol\n",
    "num_cv_rnds = 2\n",
    "lag_n = 30\n",
    "koopman_wham = True\n",
    "n_max_descriptors = 1\n",
    "l_max_descriptor = 1\n",
    "alpha_rematch = 0.5\n",
    "ncv = 3\n",
    "min_cv = 2\n",
    "direct_bias = False\n",
    "\n",
    "max_cv_basis_fun = 2000\n",
    "\n",
    "bias_num_points = 5e4\n",
    "cv_num_points = 5e4\n",
    "num_sample_rounds = 5\n",
    "\n",
    "\n",
    "n_max = 1e4  # 30**3\n",
    "\n",
    "max_blocks = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_cv():\n",
    "    import jax.numpy as jnp\n",
    "\n",
    "    from IMLCV.base.CV import CV, CvTrans\n",
    "    from IMLCV.implementations.CV import LatticeInvariants2, _cv_index, get_sinkhorn_divergence_2, sb_descriptor\n",
    "    from IMLCV.implementations.CvDiscovery import TransformerMAF\n",
    "\n",
    "    print(\"getting descriptor\")\n",
    "\n",
    "    descriptor = sb_descriptor(\n",
    "        r_cut=r_cut,\n",
    "        n_max=n_max_descriptors,\n",
    "        l_max=l_max_descriptor,\n",
    "        reshape=True,\n",
    "        reduce=True,\n",
    "    )\n",
    "\n",
    "    rounds = scheme.rounds\n",
    "\n",
    "    dlo_0 = rounds.data_loader(\n",
    "        cv_round=0,\n",
    "        start=0,\n",
    "        weight=False,\n",
    "        new_r_cut=r_cut,\n",
    "        time_series=True,\n",
    "        lag_n=20,\n",
    "    )\n",
    "\n",
    "    # print(f\"{dlo.nl=} {dlo.sp=}\")\n",
    "\n",
    "    print(\"computing soap descriptor\")\n",
    "\n",
    "    cv_0, cv_0_t = dlo_0.apply_cv(\n",
    "        descriptor,\n",
    "        x=dlo_0.sp,\n",
    "        x_t=dlo_0.sp,\n",
    "        nl=dlo_0.nl,\n",
    "        nl_t=dlo_0.nl,\n",
    "        macro_chunk=macro_chunk,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    print(\"sinkhorn div\")\n",
    "    tr = get_sinkhorn_divergence_2(\n",
    "        nli=dlo_0.nl,\n",
    "        pi=CV.stack(*[a[-1] for a in cv_0]),\n",
    "        alpha_rematch=alpha_rematch,\n",
    "        normalize=False,\n",
    "        scale_eps=\"mean\",\n",
    "        jacobian=scheme.rounds.cv > 0,\n",
    "    )\n",
    "\n",
    "    cv_1, cv_1_t = dlo_0.apply_cv(\n",
    "        tr,\n",
    "        x=cv_0,\n",
    "        x_t=cv_0_t,\n",
    "        nl=dlo_0.nl,\n",
    "        nl_t=dlo_0.nl,\n",
    "        macro_chunk=macro_chunk,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    cv_2 = cv_1\n",
    "    cv_2_t = cv_1_t\n",
    "\n",
    "    print(\"computing nonzero elems\")\n",
    "\n",
    "    cv_2_stack = CV.stack(*cv_2)\n",
    "\n",
    "    idx = jnp.argwhere(jnp.all(jnp.abs(cv_2_stack.cv) > 1e-7, axis=0))\n",
    "\n",
    "    @vmap_decorator\n",
    "    def f(x):\n",
    "        return jnp.ravel_multi_index(x, cv_2_stack.shape[1:], mode=\"wrap\")\n",
    "\n",
    "    idx = f(idx)\n",
    "\n",
    "    print(f\"{idx.shape=}\")\n",
    "\n",
    "    sl = CvTrans.from_cv_function(_cv_index, indices=idx)\n",
    "\n",
    "    cv_3, cv_3_t = dlo_0.apply_cv(\n",
    "        sl,\n",
    "        x=cv_2,\n",
    "        x_t=cv_2_t,\n",
    "        macro_chunk=macro_chunk,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    tf = TransformerMAF(\n",
    "        outdim=ncv,\n",
    "        descriptor=None,\n",
    "        pre_scale=False,\n",
    "        correlation=True,\n",
    "        correct_bias=True,\n",
    "        use_ground_bias=True,\n",
    "        T_scale=T_Scale,\n",
    "        koopman_weighting=False,\n",
    "        method=\"tcca\",\n",
    "        solver=\"eig\",\n",
    "        max_features=max_cv_basis_fun,\n",
    "        max_features_pre=max_cv_basis_fun,  # if scheme0.rounds.cv > 0 else 100,\n",
    "        trans=None,\n",
    "        eps=1e-8,\n",
    "        eps_pre=1e-5,\n",
    "    )\n",
    "\n",
    "    cv_4, cv_4_t, trans_km, _ = tf._fit(\n",
    "        x=cv_3,\n",
    "        x_t=cv_3_t,\n",
    "        w=dlo_0._weights,\n",
    "        dlo=dlo_0,\n",
    "        max_features=2000,\n",
    "        max_features_pre=2000,\n",
    "        out_dim=-1,\n",
    "    )\n",
    "\n",
    "    tot_flow = (descriptor * tr * sl * trans_km) + LatticeInvariants2\n",
    "\n",
    "    print(\"testing comp\")\n",
    "\n",
    "    cv_out, cv_out_t = dlo_0.apply_cv(\n",
    "        tot_flow,\n",
    "        x=dlo_0.sp,\n",
    "        x_t=dlo_0.sp,\n",
    "        nl=dlo_0.nl,\n",
    "        nl_t=dlo_0.nl,\n",
    "        macro_chunk=macro_chunk,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    start = 1\n",
    "\n",
    "    if scheme.rounds.cv == 0:\n",
    "        start = 0\n",
    "\n",
    "    if scheme.rounds.cv == 1:\n",
    "        start = 1\n",
    "\n",
    "    scheme.update_CV(\n",
    "        dlo_kwargs=dict(\n",
    "            out=cv_num_points,\n",
    "            num_cv_rounds=1,\n",
    "            time_series=True,\n",
    "            new_r_cut=r_cut,\n",
    "            num=num_cv_rnds + 1,\n",
    "            start=start,\n",
    "            lag_n=lag_n,\n",
    "            split_data=False,\n",
    "            chunk_size=chunk_size,\n",
    "            only_finished=True,\n",
    "            T_scale=T_Scale,\n",
    "            macro_chunk=macro_chunk,\n",
    "            samples_per_bin=samples_per_bin,\n",
    "            min_samples_per_bin=min_samples_per_bin,\n",
    "            macro_chunk_nl=macro_chunk_nl,\n",
    "            verbose=True,\n",
    "            n_max=n_max,\n",
    "            weight=True,\n",
    "            only_update_nl=True,\n",
    "            # reweight_to_fes=True,\n",
    "            reweight_inverse_bincount=True,\n",
    "            scale_times=False,\n",
    "        ),\n",
    "        transformer=TransformerMAF(\n",
    "            outdim=ncv,\n",
    "            descriptor=tot_flow,\n",
    "            pre_scale=False,\n",
    "            correct_bias=True,\n",
    "            use_ground_bias=True,\n",
    "            T_scale=T_Scale,\n",
    "            koopman_weighting=False,\n",
    "            method=\"tcca\",\n",
    "            solver=\"eig\",\n",
    "            max_features=max_cv_basis_fun,\n",
    "            max_features_pre=max_cv_basis_fun,  # if scheme0.rounds.cv > 0 else 100,\n",
    "            trans=None,\n",
    "            eps=1e-8,\n",
    "            eps_pre=1e-5,\n",
    "        ),\n",
    "        chunk_size=chunk_size,\n",
    "        plot=True,\n",
    "        new_r_cut=r_cut,\n",
    "        save_samples=True,\n",
    "        save_multiple_cvs=False,\n",
    "        test=False,\n",
    "        percentile=10,  # get 99.9% of the points\n",
    "        max_bias=max_bias,\n",
    "        macro_chunk=macro_chunk,\n",
    "        verbose=True,\n",
    "        n_max=n_max,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "def sample(eps=0.1):\n",
    "    cv_dim = scheme.rounds.get_collective_variable().n\n",
    "\n",
    "    n_umbrella = int(jnp.floor(max_blocks ** (1 / cv_dim)))\n",
    "\n",
    "    if n_umbrella > 30:\n",
    "        n_umbrella = 30\n",
    "\n",
    "    print(f\"n_umbrella: {n_umbrella}\")\n",
    "\n",
    "    scheme.inner_loop(\n",
    "        n=n_umbrella,\n",
    "        rnds=num_sample_rounds if scheme.rounds.cv > 1 else 2,\n",
    "        steps=1000,\n",
    "        init=0,\n",
    "        eps_umbrella=eps,\n",
    "        fes_bias_rnds=num_cv_rnds,\n",
    "        chunk_size=chunk_size,\n",
    "        macro_chunk=macro_chunk,\n",
    "        samples_per_bin=samples_per_bin,\n",
    "        min_samples_per_bin=min_samples_per_bin,\n",
    "        max_bias=max_bias,\n",
    "        n_max_fes=n_max,\n",
    "        convergence_kl=0.05,\n",
    "        thermolib=False,\n",
    "        T_scale=T_Scale,\n",
    "        koopman=koopman,\n",
    "        koopman_wham=koopman_wham,\n",
    "        out=bias_num_points,\n",
    "        direct_bias=direct_bias,\n",
    "        first_round_without_bias=scheme.rounds.cv == 1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fes_bias():\n",
    "    bias = scheme.FESBias(\n",
    "        plot=True,\n",
    "        samples_per_bin=samples_per_bin,\n",
    "        min_samples_per_bin=min_samples_per_bin,\n",
    "        chunk_size=chunk_size,\n",
    "        macro_chunk=macro_chunk,\n",
    "        num_rnds=num_cv_rnds,\n",
    "        vmax=max_bias,\n",
    "        max_bias=max_bias,\n",
    "        only_finished=True,\n",
    "        n_max=n_max,\n",
    "        thermolib=False,\n",
    "        out=bias_num_points,\n",
    "        T_scale=T_Scale,\n",
    "        # divide_by_histogram=True,\n",
    "        lag_n=lag_n,\n",
    "        koopman_wham=koopman_wham,\n",
    "        koopman=koopman,\n",
    "        direct_bias=direct_bias,\n",
    "    )\n",
    "\n",
    "    scheme.rounds.add_round(bias=bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_umbrella: 7\n",
      "cv_round=3\n",
      "grid=[Array([0.        , 0.04545455, 0.09090909, 0.13636364, 0.18181818,\n",
      "       0.22727273, 0.27272727, 0.31818182, 0.36363636, 0.40909091,\n",
      "       0.45454545, 0.5       , 0.54545455, 0.59090909, 0.63636364,\n",
      "       0.68181818, 0.72727273, 0.77272727, 0.81818182, 0.86363636,\n",
      "       0.90909091, 0.95454545, 1.        ], dtype=float64), Array([0.        , 0.04545455, 0.09090909, 0.13636364, 0.18181818,\n",
      "       0.22727273, 0.27272727, 0.31818182, 0.36363636, 0.40909091,\n",
      "       0.45454545, 0.5       , 0.54545455, 0.59090909, 0.63636364,\n",
      "       0.68181818, 0.72727273, 0.77272727, 0.81818182, 0.86363636,\n",
      "       0.90909091, 0.95454545, 1.        ], dtype=float64)]\n",
      "k*kjmol=Array([0.00094768, 0.00094768], dtype=float64)\n",
      "len(biases)=484\n",
      "got exception  while collecting md 21, round 1, cv 4, marking as invalid\n",
      "cannot invalidate data for c=4 r=1 i=21 because traj file does not exist\n"
     ]
    }
   ],
   "source": [
    "if scheme.rounds.cv == 0:\n",
    "    update_cv()\n",
    "\n",
    "for i in range(10):\n",
    "    sample(eps=eps)\n",
    "    update_cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_fes_bias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
